{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import torchvision.transforms.functional as func\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(mode):\n",
    "    if mode == 'train':\n",
    "        img = pd.read_csv('train_img.csv')\n",
    "        label = pd.read_csv('train_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)\n",
    "    else:\n",
    "        img = pd.read_csv('test_img.csv')\n",
    "        label = pd.read_csv('test_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyLoader(data.Dataset):\n",
    "    def __init__(self, root, mode):\n",
    "    \n",
    "        self.root = root\n",
    "        # the type is numpy.ndarray\n",
    "        self.img_name, self.label = getData(mode)\n",
    "        self.mode = mode\n",
    "        print(\"> Found %d images...\" % (len(self.img_name)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Step 1.Get the image path from 'self.img_name' and load it\n",
    "        path = self.root + self.img_name[index] + '.jpeg' \n",
    "        img  = Image.open(path).convert('RGB')\n",
    "        \n",
    "        # Step 2.Get the ground truth label\n",
    "        label = self.label[index]\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "#         transforms.ToPILImage(),\n",
    "        transforms.ToTensor()])\n",
    "#         transforms.RandomCrop((300,300))])\n",
    "        \n",
    "        # Step 3.Transform the .jpeg rgb images\n",
    "        img = transform(img)\n",
    "        img = torch.unsqueeze(img, 0)\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "#         img = transforms.Normalize(img,(0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         img = torchvision.transforms.ToPILImage(img)\n",
    "#         img = torchvision.transforms.ToTensor()(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 28099 images...\n"
     ]
    }
   ],
   "source": [
    "reti_loader = RetinopathyLoader(\"/home/wang/Desktop/Auberon/LAB3/data/\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        # maxpool 處理\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "#         self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        self.linear = nn.Linear(in_features=51200, out_features=1000, bias=True)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # maxpool處理\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = F.avg_pool2d(out, 4)\n",
    "        out = F.avg_pool2d(out, kernel_size=7, stride=1, padding=0)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# ResNet架構來源 https://zhuanlan.zhihu.com/p/31852747\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "#     y = net(torch.randn(1,3,32,32))\n",
    "    y = net(reti_loader[0][0])\n",
    "    print(y.size())\n",
    "    print(y)\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 呼叫ResNet18\n",
    "net = ResNet18()\n",
    "# GPU運算\n",
    "net.to(device)\n",
    "# loss function\n",
    "loss_fun = F.cross_entropy\n",
    "# optimizer \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-2)\n",
    "# 起始running_loss\n",
    "running_loss = 0.0\n",
    "\n",
    "# 計算ACC\n",
    "true_ans = 0.0\n",
    "false_ans = 0.0\n",
    "\n",
    "# Number of train data\n",
    "# num_train = 28099\n",
    "num_train = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18_train(n):\n",
    "    running_loss = 0.0\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        inputs = reti_loader[i][0].to(device)\n",
    "        labels = reti_loader[i][1].to(device)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        labels = torch.unsqueeze(labels, 0)\n",
    "        output = loss_fun(outputs, labels)\n",
    "        output.backward()\n",
    "        output\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss =+ output.cpu().data.numpy()\n",
    "        net.eval()\n",
    "\n",
    "        result = output\n",
    "\n",
    "        ground_true = labels.cpu().detach().numpy()[0]\n",
    "        pred_y = np.round(result.cpu().detach().numpy())\n",
    "        confusion_yTrue.append(ground_true)\n",
    "        confusion_yPred.append(pred_y)\n",
    "        \n",
    "        if ground_true == pred_y:\n",
    "            true_ans = true_ans + 1\n",
    "        else:\n",
    "            false_ans = false_ans + 1\n",
    "    return true_ans, false_ans, confusion_yTrue, confusion_yPred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch 1\n",
      "The ACC is : 0.618\n",
      "This is epoch 2\n",
      "The ACC is : 0.665\n",
      "This is epoch 3\n",
      "The ACC is : 0.698\n",
      "This is epoch 4\n",
      "The ACC is : 0.719\n",
      "This is epoch 5\n",
      "The ACC is : 0.729\n",
      "This is epoch 6\n",
      "The ACC is : 0.74\n",
      "This is epoch 7\n",
      "The ACC is : 0.755\n",
      "This is epoch 8\n",
      "The ACC is : 0.765\n",
      "This is epoch 9\n",
      "The ACC is : 0.771\n",
      "This is epoch 10\n",
      "The ACC is : 0.781\n"
     ]
    }
   ],
   "source": [
    "# 運算\n",
    "epoch_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_list.append(epoch)\n",
    "    print (\"This is epoch \"+ str(epoch+1))\n",
    "    \n",
    "    result = ResNet18_train(num_train)\n",
    "    y_test = result[2]\n",
    "    y_pred = result[3]\n",
    "    ACC = (result[0]/(result[0]+result[1]))\n",
    "    \n",
    "    acc_list.append(ACC)\n",
    "    print (\"The ACC is : \"+str(ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = np.array(y_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.array(y_pred).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = y_test\n",
    "y_pred = y_pred\n",
    "df_confusion = confusion_matrix(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(df_confusion, classes = ['0','1','2','3','4'],title=None, normalize=False,cmap=plt.cm.Blues):\n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "plot_confusion_matrix(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
