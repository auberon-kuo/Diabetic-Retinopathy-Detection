{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "import torchvision.transforms.functional as func\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(mode):\n",
    "    if mode == 'train':\n",
    "        img = pd.read_csv('train_img.csv')\n",
    "        label = pd.read_csv('train_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)\n",
    "    else:\n",
    "        img = pd.read_csv('test_img.csv')\n",
    "        label = pd.read_csv('test_label.csv')\n",
    "        return np.squeeze(img.values), np.squeeze(label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinopathyLoader(data.Dataset):\n",
    "    def __init__(self, root, mode):\n",
    "    \n",
    "        self.root = root\n",
    "        # the type is numpy.ndarray\n",
    "        self.img_name, self.label = getData(mode)\n",
    "        self.mode = mode\n",
    "        print(\"> Found %d images...\" % (len(self.img_name)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Step 1.Get the image path from 'self.img_name' and load it\n",
    "        path = self.root + self.img_name[index] + '.jpeg' \n",
    "        img  = Image.open(path).convert('RGB')\n",
    "        \n",
    "        # Step 2.Get the ground truth label\n",
    "        label = self.label[index]\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "#         transforms.ToPILImage(),\n",
    "        transforms.ToTensor()])\n",
    "#         transforms.RandomCrop((300,300))])\n",
    "        \n",
    "        # Step 3.Transform the .jpeg rgb images\n",
    "        img = transform(img)\n",
    "        img = torch.unsqueeze(img, 0)\n",
    "        label = torch.from_numpy(np.array(label))\n",
    "#         img = transforms.Normalize(img,(0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "#         img = torchvision.transforms.ToPILImage(img)\n",
    "#         img = torchvision.transforms.ToTensor()(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "#         self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        \n",
    "        # maxpool 處理\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "#         self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        self.linear = nn.Linear(in_features=204800, out_features=1000, bias=True)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # maxpool處理\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "#         out = F.avg_pool2d(out, 4)\n",
    "        out = F.avg_pool2d(out, kernel_size=7, stride=1, padding=0)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# ResNet架構來源 https://zhuanlan.zhihu.com/p/31852747\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3,4,6,3])\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "#     y = net(torch.randn(1,3,32,32))\n",
    "    y = net(reti_loader[0][0])\n",
    "    print(y.size())\n",
    "    print(y)\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 28099 images...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "reti_loader = RetinopathyLoader(\"/home/wang/Desktop/Auberon/LAB3/data/\", \"train\")\n",
    "\n",
    "# 呼叫ResNet50\n",
    "net = ResNet50()\n",
    "# GPU運算\n",
    "net.to(device)\n",
    "# loss function\n",
    "loss_fun = F.cross_entropy\n",
    "# optimizer \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-2)\n",
    "# 起始running_loss\n",
    "running_loss = 0.0\n",
    "\n",
    "# 計算ACC\n",
    "true_ans = 0.0\n",
    "false_ans = 0.0\n",
    "\n",
    "# Number of train data\n",
    "# num_train = 28099\n",
    "num_train = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50_train(n):\n",
    "    running_loss = 0.0\n",
    "    true_ans = 0.0\n",
    "    false_ans = 0.0\n",
    "    confusion_yTrue = []\n",
    "    confusion_yPred = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        inputs = reti_loader[i][0].to(device)\n",
    "        labels = reti_loader[i][1].to(device)\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        labels = torch.unsqueeze(labels, 0)\n",
    "        output = loss_fun(outputs, labels)\n",
    "        output.backward()\n",
    "        output\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss =+ output.cpu().data.numpy()\n",
    "        net.eval()\n",
    "\n",
    "        result = output\n",
    "\n",
    "        ground_true = labels.cpu().detach().numpy()[0]\n",
    "        pred_y = np.round(result.cpu().detach().numpy())\n",
    "        confusion_yTrue.append(ground_true)\n",
    "        confusion_yPred.append(pred_y)\n",
    "        \n",
    "        if ground_true == pred_y:\n",
    "            true_ans = true_ans + 1\n",
    "        else:\n",
    "            false_ans = false_ans + 1\n",
    "    return true_ans, false_ans, confusion_yTrue, confusion_yPred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is epoch 1\n",
      "The ACC is : 0.623\n",
      "This is epoch 2\n",
      "The ACC is : 0.666\n",
      "This is epoch 3\n",
      "The ACC is : 0.698\n",
      "This is epoch 4\n",
      "The ACC is : 0.718\n",
      "This is epoch 5\n",
      "The ACC is : 0.727\n",
      "This is epoch 6\n",
      "The ACC is : 0.735\n",
      "This is epoch 7\n",
      "The ACC is : 0.739\n",
      "This is epoch 8\n",
      "The ACC is : 0.758\n",
      "This is epoch 9\n",
      "The ACC is : 0.767\n",
      "This is epoch 10\n",
      "The ACC is : 0.774\n"
     ]
    }
   ],
   "source": [
    "# 運算\n",
    "epoch_list = []\n",
    "acc_list = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    epoch_list.append(epoch)\n",
    "    print (\"This is epoch \"+ str(epoch+1))\n",
    "    \n",
    "    result = ResNet50_train(num_train)\n",
    "    y_test = result[2]\n",
    "    y_pred = result[3]\n",
    "    ACC = (result[0]/(result[0]+result[1]))\n",
    "    \n",
    "    acc_list.append(ACC)\n",
    "    print (\"The ACC is : \"+str(ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu = y_test\n",
    "y_pred = y_pred\n",
    "df_confusion = confusion_matrix(y_actu, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(df_confusion, classes = ['0','1','2','3','4'],title=None, normalize=False,cmap=plt.cm.Blues):\n",
    "    plt.matshow(df_confusion, cmap=cmap) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "plot_confusion_matrix(df_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
